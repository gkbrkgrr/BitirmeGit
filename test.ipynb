{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d9056c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from collections import defaultdict\n",
    "from wrf import getvar, ALL_TIMES, interplevel, to_np, latlon_coords, get_cartopy, extract_times, ll_to_xy, to_np\n",
    "from functions.listwrfouts import listWrfouts\n",
    "from functions.injectmissincoords import inject_missing_coordinates_from_geo_em\n",
    "from functions.plots import plot_T2_15facet, plot_PSFC_15facet, plot_TP_15facet, plot_WS10_15facet, plot_RH2_15facet\n",
    "from functions.get_point_data import get_point_data\n",
    "from functions.errors import *\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import gc\n",
    "import pandas as pd\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import cmaps\n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ed1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_set(set_name, base_dir, geo_em_base):\n",
    "    archive_path = os.path.join(base_dir, set_name, f\"{set_name}_wrfouts.tar.gz\")\n",
    "    extract_dir = os.path.join(base_dir, set_name, \"temp_extract_dir\")\n",
    "\n",
    "    files = listWrfouts(archive_path, extract_dir)\n",
    "    print(f\"Listing wrfouts from {archive_path}\")\n",
    "    domain_files = defaultdict(list)\n",
    "    for f in files:\n",
    "        if \"d01\" in os.path.basename(f):\n",
    "            domain_files[\"d01\"].append(f)\n",
    "        elif \"d02\" in os.path.basename(f):\n",
    "            domain_files[\"d02\"].append(f)\n",
    "\n",
    "    result = defaultdict(list)\n",
    "    print(f\"Listed wrfouts from {archive_path}\")\n",
    "\n",
    "    for dom in domain_files:\n",
    "        domain_files[dom] = sorted(domain_files[dom])\n",
    "        geo_em_path = os.path.join(geo_em_base, f\"geo_em.{dom}.nc\")\n",
    "        for file in domain_files[dom]:\n",
    "            print(f\"Injecting missing values into {file}, from {geo_em_path}\")\n",
    "            inject_missing_coordinates_from_geo_em(file, geo_em_path)\n",
    "        result[dom] = [Dataset(path, mode=\"r\") for path in domain_files[dom]]\n",
    "\n",
    "    return set_name, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c519a5",
   "metadata": {},
   "source": [
    "# Read WRF outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1437d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"D:\\istanbul_wrfouts\\20012024\"\n",
    "sets = [f\"SET{i}\" for i in range(1, 16)]\n",
    "df = {}\n",
    "\n",
    "for set in sets:\n",
    "    df[set] = {\"d01\": [], \"d02\": []}\n",
    "    \n",
    "    wrfouts_list = listWrfouts(os.path.join(base_dir, set, f\"{set}_wrfouts.tar.gz\"), os.path.join(base_dir, set, \"temp_extract_dir\"))\n",
    "    for f in wrfouts_list:\n",
    "        if \"d01\" in os.path.basename(f):\n",
    "            df[set][\"d01\"].append(Dataset(f))\n",
    "        elif \"d02\" in os.path.basename(f):\n",
    "            df[set][\"d02\"].append(Dataset(f))\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a556c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"D:\\istanbul_wrfouts\\20012024\"\n",
    "geo_em_base = r\"D:\\istanbul_wrfouts\"\n",
    "sets = [f\"SET{i}\" for i in range(1, 16)]\n",
    "\n",
    "df = {}\n",
    "\n",
    "for set in sets:\n",
    "    set_name, data = process_set(set, base_dir, geo_em_base)\n",
    "    df[set_name] = data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085e4a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(1, 16):\n",
    "    try:\n",
    "        set = \"SET\"+str(i)\n",
    "        get_point_data(df[set][\"d02\"], \"t2\", 41.223333,29.165833)\n",
    "    except:\n",
    "        print(f\"SET{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a44d3",
   "metadata": {},
   "source": [
    "# Read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e19425",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.arange(72)\n",
    "T2 = 17.5 + 7.5 * np.sin(2 * np.pi * hours / 24 - np.pi / 2)  \n",
    "T2 = np.round(T2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2ba26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_to_csv(case: str, variable: str):\n",
    "    \"\"\"\n",
    "    Obs verinin eklenmesi lazım. Her istasyon için ayrı obs gelecek. Belki yeni bir mapping uygulanabilir?  \n",
    "    \"\"\"\n",
    "\n",
    "    csv_files_path = os.path.join(os.getcwd(), \"csv_files\")\n",
    "    results = pd.DataFrame(columns=[\"Physics\", \"MAE\", \"RMSE\", \"Bias\"])\n",
    "    safe_variable = re.sub(r'[<>:\"/\\\\|?*]', '_', variable)\n",
    "\n",
    "    for physics in sets_mapping[\"physics\"]: \n",
    "        matching_files = []\n",
    "        df = {}\n",
    "\n",
    "        if os.path.isdir(csv_files_path):\n",
    "            for filename in os.listdir(csv_files_path):\n",
    "                if f\"case_{case}\" in filename and f\"{physics}\" in filename and filename.endswith(\".csv\"):\n",
    "                    matching_files.append(os.path.join(csv_files_path, filename))\n",
    "\n",
    "        for file in matching_files:\n",
    "            station_id = file.split(\"station_\")[1].split(\".\")[0]\n",
    "            df[station_id] = pd.read_csv(file)\n",
    "\n",
    "        results_for_each_physics = pd.DataFrame(columns=[\"StationId\", \"MAE\", \"RMSE\", \"Bias\"])\n",
    "        for station_id in df.keys():\n",
    "            results_for_each_physics.loc[len(results_for_each_physics)] = {\n",
    "            \"StationId\": str(station_id),\n",
    "            \"MAE\": compute_mae(df[station_id][variable], T2),\n",
    "            \"RMSE\": compute_rmse(df[station_id][variable], T2),\n",
    "            \"Bias\": compute_bias(df[station_id][variable], T2)\n",
    "            }\n",
    "        \n",
    "        results.loc[len(results)] = {\n",
    "            \"Physics\": physics,\n",
    "            \"MAE\": round(np.nanmean(results_for_each_physics[\"MAE\"]), 4),\n",
    "            \"RMSE\": round(np.nanmean(results_for_each_physics[\"RMSE\"]), 4),\n",
    "            \"Bias\": round(np.nanmean(results_for_each_physics[\"Bias\"]), 4),\n",
    "            }\n",
    "        \n",
    "        error_csvs_path = os.path.join(os.getcwd(), \"error_csvs\")\n",
    "        os.makedirs(error_csvs_path, exist_ok=True)\n",
    "        \n",
    "        results.to_csv(os.path.join(error_csvs_path, f\"{case}_{safe_variable}.csv\"), index=False, float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2baadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"csv_files\")\n",
    "case = \"20241123\"\n",
    "results = pd.DataFrame(columns=[\"Physics\", \"MAE\", \"RMSE\", \"Bias\"])\n",
    "for physics in sets_mapping[\"physics\"]: \n",
    "    matching_files = []\n",
    "    df = {}\n",
    "\n",
    "    if os.path.isdir(csv_path):\n",
    "        for filename in os.listdir(csv_path):\n",
    "            if f\"case_{case}\" in filename and f\"{physics}\" in filename and filename.endswith(\".csv\"):\n",
    "                matching_files.append(os.path.join(csv_path, filename))\n",
    "\n",
    "    for file in matching_files:\n",
    "        station_id = file.split(\"station_\")[1].split(\".\")[0]\n",
    "        df[station_id] = pd.read_csv(file)\n",
    "\n",
    "    results_for_each_physics = pd.DataFrame(columns=[\"StationId\", \"MAE\", \"RMSE\", \"Bias\"])\n",
    "    for station_id in df.keys():\n",
    "        results_for_each_physics.loc[len(results_for_each_physics)] = {\n",
    "        \"StationId\": str(station_id),\n",
    "        \"MAE\": compute_mae(df[station_id][\"2_Metre_Sicaklik(C)\"], T2),\n",
    "        \"RMSE\": compute_rmse(df[station_id][\"2_Metre_Sicaklik(C)\"], T2),\n",
    "        \"Bias\": compute_bias(df[station_id][\"2_Metre_Sicaklik(C)\"], T2)\n",
    "        }\n",
    "    \n",
    "    results.loc[len(results)] = {\n",
    "        \"Physics\": physics,\n",
    "        \"MAE\": round(np.nanmean(results_for_each_physics[\"MAE\"]), 4),\n",
    "        \"RMSE\": round(np.nanmean(results_for_each_physics[\"RMSE\"]), 4),\n",
    "        \"Bias\": round(np.nanmean(results_for_each_physics[\"Bias\"]), 4),\n",
    "        }\n",
    "    results.to_csv(\"model_evaluation_results.csv\", index=False, float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ab7e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"2_Metre_Sicaklik(C)\", \"10_Metre_Ruzgar(m/s)\", \"Yagis(mm)\"]\n",
    "case = \"20241123\"\n",
    "for variable in variables:\n",
    "    errors_to_csv(case=case, variable=variable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
