{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9056c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from collections import defaultdict\n",
    "from wrf import getvar, ALL_TIMES, interplevel, to_np, latlon_coords, get_cartopy, extract_times, ll_to_xy, to_np\n",
    "from functions.listwrfouts import listWrfouts\n",
    "from functions.injectmissincoords import inject_missing_coordinates_from_geo_em\n",
    "from functions.plots import plot_T2_15facet, plot_PSFC_15facet, plot_TP_15facet, plot_WS10_15facet, plot_RH2_15facet\n",
    "from functions.get_point_data import get_point_data\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import gc\n",
    "import pandas as pd\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import cmaps\n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ed1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_set(set_name, base_dir, geo_em_base):\n",
    "    archive_path = os.path.join(base_dir, set_name, f\"{set_name}_wrfouts.tar.gz\")\n",
    "    extract_dir = os.path.join(base_dir, set_name, \"temp_extract_dir\")\n",
    "\n",
    "    files = listWrfouts(archive_path, extract_dir)\n",
    "    print(f\"Listing wrfouts from {archive_path}\")\n",
    "    domain_files = defaultdict(list)\n",
    "    for f in files:\n",
    "        if \"d01\" in os.path.basename(f):\n",
    "            domain_files[\"d01\"].append(f)\n",
    "        elif \"d02\" in os.path.basename(f):\n",
    "            domain_files[\"d02\"].append(f)\n",
    "\n",
    "    result = defaultdict(list)\n",
    "    print(f\"Listed wrfouts from {archive_path}\")\n",
    "\n",
    "    for dom in domain_files:\n",
    "        domain_files[dom] = sorted(domain_files[dom])\n",
    "        geo_em_path = os.path.join(geo_em_base, f\"geo_em.{dom}.nc\")\n",
    "        for file in domain_files[dom]:\n",
    "            print(f\"Injecting missing values into {file}, from {geo_em_path}\")\n",
    "            inject_missing_coordinates_from_geo_em(file, geo_em_path)\n",
    "        result[dom] = [Dataset(path, mode=\"r\") for path in domain_files[dom]]\n",
    "\n",
    "    return set_name, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c519a5",
   "metadata": {},
   "source": [
    "# Read WRF outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1437d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"D:\\istanbul_wrfouts\\20012024\"\n",
    "sets = [f\"SET{i}\" for i in range(1, 16)]\n",
    "df = {}\n",
    "\n",
    "for set in sets:\n",
    "    df[set] = {\"d01\": [], \"d02\": []}\n",
    "    \n",
    "    wrfouts_list = listWrfouts(os.path.join(base_dir, set, f\"{set}_wrfouts.tar.gz\"), os.path.join(base_dir, set, \"temp_extract_dir\"))\n",
    "    for f in wrfouts_list:\n",
    "        if \"d01\" in os.path.basename(f):\n",
    "            df[set][\"d01\"].append(Dataset(f))\n",
    "        elif \"d02\" in os.path.basename(f):\n",
    "            df[set][\"d02\"].append(Dataset(f))\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a556c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"D:\\istanbul_wrfouts\\20012024\"\n",
    "geo_em_base = r\"D:\\istanbul_wrfouts\"\n",
    "sets = [f\"SET{i}\" for i in range(1, 16)]\n",
    "\n",
    "df = {}\n",
    "\n",
    "for set in sets:\n",
    "    set_name, data = process_set(set, base_dir, geo_em_base)\n",
    "    df[set_name] = data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6085e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 16):\n",
    "    try:\n",
    "        set = \"SET\"+str(i)\n",
    "        get_point_data(df[set][\"d02\"], \"t2\", 41.223333,29.165833)\n",
    "    except:\n",
    "        print(f\"SET{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a44d3",
   "metadata": {},
   "source": [
    "# Read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_mapping = pd.DataFrame([\n",
    "    {\"set_name\": \"SET1\", \"physics\": \"mp4_pbl1\"},\n",
    "    {\"set_name\": \"SET2\", \"physics\": \"mp4_pbl5\"},\n",
    "    {\"set_name\": \"SET3\", \"physics\": \"mp4_pbl7\"},\n",
    "    {\"set_name\": \"SET4\", \"physics\": \"mp6_pbl1\"},\n",
    "    {\"set_name\": \"SET5\", \"physics\": \"mp6_pbl5\"},\n",
    "    {\"set_name\": \"SET6\", \"physics\": \"mp6_pbl7\"},\n",
    "    {\"set_name\": \"SET7\", \"physics\": \"mp38_pbl1\"},\n",
    "    {\"set_name\": \"SET8\", \"physics\": \"mp38_pbl5\"},\n",
    "    {\"set_name\": \"SET9\", \"physics\": \"mp38_pbl7\"},\n",
    "    {\"set_name\": \"SET10\", \"physics\": \"mp10_pbl1\"},\n",
    "    {\"set_name\": \"SET11\", \"physics\": \"mp10_pbl5\"},\n",
    "    {\"set_name\": \"SET12\", \"physics\": \"mp10_pbl7\"},\n",
    "    {\"set_name\": \"SET13\", \"physics\": \"mp24_pbl1\"},\n",
    "    {\"set_name\": \"SET14\", \"physics\": \"mp24_pbl5\"},\n",
    "    {\"set_name\": \"SET15\", \"physics\": \"mp24_pbl7\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2baadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"csv_files\")\n",
    "case = \"20241123\"\n",
    "station = \"17061\"\n",
    "\n",
    "matching_files = []\n",
    "df = {}\n",
    "\n",
    "if os.path.isdir(csv_path):\n",
    "    for filename in os.listdir(csv_path):\n",
    "        if f\"case_{case}\" in filename and f\"station_{station}\" in filename and filename.endswith(\".csv\"):\n",
    "            matching_files.append(os.path.join(csv_path, filename))\n",
    "\n",
    "for file in matching_files:\n",
    "    physics = f'{os.path.basename(file).split(\"_\")[2]}_{os.path.basename(file).split(\"_\")[3]}'\n",
    "    set_name = sets_mapping.loc[sets_mapping[\"physics\"] == physics, \"set_name\"].iloc[0]\n",
    "    \n",
    "    df[set_name] = pd.read_csv(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
